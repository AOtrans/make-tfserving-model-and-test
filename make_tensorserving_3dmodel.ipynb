{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import PIL.Image as Image\n",
    "import cv2\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASS=3\n",
    "CROP_SIZE=160\n",
    "NUM_FRAMES_PER_CLIP=16\n",
    "BATCH_SIZE=10\n",
    "RGB_CHANNEL=3\n",
    "IS_TRAIN=True\n",
    "BLOCK_EXPANSION=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_weight(name,kshape,wd=0.0005*0.3*0.3):\n",
    "    with tf.device('/cpu:0'):\n",
    "        var=tf.get_variable(name,shape=kshape,initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "    if wd!=0:\n",
    "        weight_decay = tf.nn.l2_loss(var)*wd\n",
    "        tf.add_to_collection('weightdecay_losses', weight_decay)\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convS(name,l_input,in_channels,out_channels):\n",
    "    return tf.nn.bias_add(tf.nn.conv3d(l_input,get_conv_weight(name=name,\n",
    "                                                               kshape=[1,3,3,in_channels,out_channels]),\n",
    "                                                               strides=[1,1,1,1,1],padding='SAME'),\n",
    "                                              get_conv_weight(name+'_bias',[out_channels],0))\n",
    "def convT(name,l_input,in_channels,out_channels):\n",
    "    return tf.nn.bias_add(tf.nn.conv3d(l_input,get_conv_weight(name=name,\n",
    "                                                               kshape=[3,1,1,in_channels,out_channels]),\n",
    "                                                               strides=[1,1,1,1,1],padding='SAME'),\n",
    "                                              get_conv_weight(name+'_bias',[out_channels],0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck():\n",
    "    def __init__(self,l_input,inplanes,planes,stride=1,downsample='',n_s=0,depth_3d=47):\n",
    "        \n",
    "        self.X_input=l_input\n",
    "        self.downsample=downsample\n",
    "        self.planes=planes\n",
    "        self.inplanes=inplanes\n",
    "        self.depth_3d=depth_3d\n",
    "        self.ST_struc=('A','B','C')\n",
    "        self.len_ST=len(self.ST_struc)\n",
    "        self.id=n_s\n",
    "        self.n_s=n_s\n",
    "        self.ST=list(self.ST_struc)[self.id % self.len_ST]\n",
    "        self.stride_p=[1,1,1,1,1]\n",
    "       \n",
    "        if self.downsample!='':\n",
    "            self.stride_p=[1,1,2,2,1]\n",
    "        if n_s<self.depth_3d:\n",
    "            if n_s==0:\n",
    "                self.stride_p=[1,1,1,1,1]\n",
    "        else:\n",
    "            if n_s==self.depth_3d:\n",
    "                self.stride_p=[1,2,2,2,1]\n",
    "            else:\n",
    "                self.stride_p=[1,1,1,1,1]\n",
    "    #P3D has three types of bottleneck sub-structions.\n",
    "    def ST_A(self,name,x):\n",
    "        x=convS(name+'_S',x,self.planes,self.planes)\n",
    "        x=tf.layers.batch_normalization(x,training=IS_TRAIN)\n",
    "        x=tf.nn.relu(x)\n",
    "        x=convT(name+'_T',x,self.planes,self.planes)\n",
    "        x=tf.layers.batch_normalization(x,training=IS_TRAIN)\n",
    "        x=tf.nn.relu(x)\n",
    "        return x\n",
    "    \n",
    "    def ST_B(self,name,x):\n",
    "        tmp_x=convS(name+'_S',x,self.planes,self.planes)\n",
    "        tmp_x=tf.layers.batch_normalization(tmp_x,training=IS_TRAIN)\n",
    "        tmp_x=tf.nn.relu(tmp_x)\n",
    "        x=convT(name+'_T',x,self.planes,self.planes)\n",
    "        x=tf.layers.batch_normalization(x,training=IS_TRAIN)\n",
    "        x=tf.nn.relu(x)\n",
    "        return x+tmp_x\n",
    "    \n",
    "    def ST_C(self,name,x):\n",
    "        x=convS(name+'_S',x,self.planes,self.planes)\n",
    "        x=tf.layers.batch_normalization(x,training=IS_TRAIN)\n",
    "        x=tf.nn.relu(x)\n",
    "        tmp_x=convT(name+'_T',x,self.planes,self.planes)\n",
    "        tmp_x=tf.layers.batch_normalization(tmp_x,training=IS_TRAIN)\n",
    "        tmp_x=tf.nn.relu(tmp_x)\n",
    "        return x+tmp_x\n",
    "    \n",
    "    def infer(self):\n",
    "        residual=self.X_input\n",
    "        if self.n_s<self.depth_3d:\n",
    "            out=tf.nn.conv3d(self.X_input,get_conv_weight('conv3_{}_1'.format(self.id),[1,1,1,self.inplanes,self.planes]),\n",
    "                             strides=self.stride_p,padding='SAME')\n",
    "            out=tf.layers.batch_normalization(out,training=IS_TRAIN)\n",
    "            \n",
    "        else:\n",
    "            param=self.stride_p\n",
    "            param.pop(1)\n",
    "            out=tf.nn.conv2d(self.X_input,get_conv_weight('conv2_{}_1'.format(self.id),[1,1,self.inplanes,self.planes]),\n",
    "                             strides=param,padding='SAME')\n",
    "            out=tf.layers.batch_normalization(out,training=IS_TRAIN)\n",
    "    \n",
    "        out=tf.nn.relu(out)    \n",
    "        if self.id<self.depth_3d:\n",
    "            if self.ST=='A':\n",
    "                out=self.ST_A('STA_{}_2'.format(self.id),out)\n",
    "            elif self.ST=='B':\n",
    "                out=self.ST_B('STB_{}_2'.format(self.id),out)\n",
    "            elif self.ST=='C':\n",
    "                out=self.ST_C('STC_{}_2'.format(self.id),out)\n",
    "        else:\n",
    "            out=tf.nn.conv2d(out,get_conv_weight('conv2_{}_2'.format(self.id),[3,3,self.planes,self.planes]),\n",
    "                                  strides=[1,1,1,1],padding='SAME')\n",
    "            out=tf.layers.batch_normalization(out,training=IS_TRAIN)\n",
    "            out=tf.nn.relu(out)\n",
    "\n",
    "        if self.n_s<self.depth_3d:\n",
    "            out=tf.nn.conv3d(out,get_conv_weight('conv3_{}_3'.format(self.id),[1,1,1,self.planes,self.planes*BLOCK_EXPANSION]),\n",
    "                             strides=[1,1,1,1,1],padding='SAME')\n",
    "            out=tf.layers.batch_normalization(out,training=IS_TRAIN)\n",
    "        else:\n",
    "            out=tf.nn.conv2d(out,get_conv_weight('conv2_{}_3'.format(self.id),[1,1,self.planes,self.planes*BLOCK_EXPANSION]),\n",
    "                             strides=[1,1,1,1],padding='SAME')\n",
    "            out=tf.layers.batch_normalization(out,training=IS_TRAIN)\n",
    "           \n",
    "        if len(self.downsample)==1:\n",
    "            residual=tf.nn.conv2d(residual,get_conv_weight('dw2d_{}'.format(self.id),[1,1,self.inplanes,self.planes*BLOCK_EXPANSION]),\n",
    "                                  strides=[1,2,2,1],padding='SAME')\n",
    "            residual=tf.layers.batch_normalization(residual,training=IS_TRAIN)\n",
    "        elif len(self.downsample)==2:\n",
    "            residual=tf.nn.conv3d(residual,get_conv_weight('dw3d_{}'.format(self.id),[1,1,1,self.inplanes,self.planes*BLOCK_EXPANSION]),\n",
    "                                  strides=self.downsample[1],padding='SAME')\n",
    "            residual=tf.layers.batch_normalization(residual,training=IS_TRAIN)\n",
    "        out+=residual\n",
    "        out=tf.nn.relu(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class make_block():\n",
    "    def __init__(self,_X,planes,num,inplanes,cnt,depth_3d=47,stride=1):\n",
    "        self.input=_X\n",
    "        self.planes=planes\n",
    "        self.inplanes=inplanes\n",
    "        self.num=num\n",
    "        self.cnt=cnt\n",
    "        self.depth_3d=depth_3d\n",
    "        self.stride=stride\n",
    "        if self.cnt<depth_3d:\n",
    "            if self.cnt==0:\n",
    "                stride_p=[1,1,1,1,1]\n",
    "            else:\n",
    "                stride_p=[1,1,2,2,1]\n",
    "            if stride!=1 or inplanes!=planes*BLOCK_EXPANSION:\n",
    "                self.downsample=['3d',stride_p]\n",
    "        else:\n",
    "            if stride!=1 or inplanes!=planes*BLOCK_EXPANSION:\n",
    "                self.downsample=['2d']\n",
    "    def infer(self):\n",
    "        x=Bottleneck(self.input,self.inplanes,self.planes,self.stride,self.downsample,n_s=self.cnt,depth_3d=self.depth_3d).infer()\n",
    "        self.cnt+=1\n",
    "        self.inplanes=BLOCK_EXPANSION*self.planes\n",
    "        for i in range(1,self.num):\n",
    "            x=Bottleneck(x,self.inplanes,self.planes,n_s=self.cnt,depth_3d=self.depth_3d).infer()\n",
    "            self.cnt+=1\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_p3d(_X):\n",
    "    cnt=0\n",
    "    conv1_custom=tf.nn.conv3d(_X,get_conv_weight('firstconv1',[1,7,7,RGB_CHANNEL,64]),strides=[1,1,2,2,1],padding='SAME')\n",
    "    conv1_custom_bn=tf.layers.batch_normalization(conv1_custom,training=IS_TRAIN)\n",
    "    conv1_custom_bn_relu=tf.nn.relu(conv1_custom_bn)\n",
    "    x=tf.nn.max_pool3d(conv1_custom_bn_relu,[1,2,3,3,1],strides=[1,2,2,2,1],padding='SAME')\n",
    "    b1=make_block(x,64,3,64,cnt)\n",
    "    x=b1.infer()\n",
    "    cnt=b1.cnt\n",
    "   \n",
    "    x=tf.nn.max_pool3d(x,[1,2,1,1,1],strides=[1,2,1,1,1],padding='SAME')\n",
    "    \n",
    "    b2=make_block(x,128,8,256,cnt,stride=2)\n",
    "    x=b2.infer()\n",
    "    cnt=b2.cnt\n",
    "    x=tf.nn.max_pool3d(x,[1,2,1,1,1],strides=[1,2,1,1,1],padding='SAME')\n",
    "    \n",
    "    b3=make_block(x,256,36,512,cnt,stride=2)\n",
    "    x=b3.infer()\n",
    "    cnt=b3.cnt\n",
    "    x=tf.nn.max_pool3d(x,[1,2,1,1,1],strides=[1,2,1,1,1],padding='SAME')\n",
    "    \n",
    "    shape=x.shape.as_list()\n",
    "    x=tf.reshape(x,shape=[-1,shape[2],shape[3],shape[4]])\n",
    "    \n",
    "    x=make_block(x,512,3,1024,cnt,stride=2).infer()\n",
    "    \n",
    "    #Caution:make sure avgpool on the input which has the same shape as kernelsize has been setted padding='VALID'\n",
    "    x=tf.nn.avg_pool(x,[1,5,5,1],strides=[1,1,1,1],padding='VALID')\n",
    "    \n",
    "    x=tf.reshape(x,shape=[-1,2048])\n",
    "    if(IS_TRAIN):\n",
    "        x=tf.nn.dropout(x,keep_prob=1)\n",
    "    else:\n",
    "        x=tf.nn.dropout(x,keep_prob=1)\n",
    "    \n",
    "    x=tf.layers.dense(x,NUM_CLASS)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_to_serving(inputs, outputs, sess, saver, export_version, export_path): \n",
    "    inputs = tf.saved_model.utils.build_tensor_info(inputs)\n",
    "    outputs = tf.saved_model.utils.build_tensor_info(outputs)\n",
    "     \n",
    "    signature = tf.saved_model.signature_def_utils.build_signature_def( \n",
    "        inputs={'x': inputs}, outputs={'logit': outputs}, \n",
    "        method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME) \n",
    "    print tf.saved_model.signature_constants.PREDICT_METHOD_NAME\n",
    "    export_path = export_path+'/'+export_version\n",
    "    builder = tf.saved_model.builder.SavedModelBuilder(export_path) \n",
    "    main_op = tf.group(tf.tables_initializer(), name='main_op')\n",
    "    builder.add_meta_graph_and_variables(sess=sess, \n",
    "                                         tags=[tf.saved_model.tag_constants.SERVING], \n",
    "                                         signature_def_map={ 'predict_image': signature}, \n",
    "                                         main_op=main_op,\n",
    "                                         saver=saver) \n",
    "    builder.save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./SC_DA_P3D_RES1010_30000-30000\n",
      "tensorflow/serving/predict\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: ./3daction/1111/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "def pretreat(param):\n",
    "    mean, variance = tf.nn.moments(param, axes=[0,1,2])\n",
    "    std = tf.sqrt(variance) \n",
    "    std = tf.maximum(std, tf.constant(1.0/np.sqrt(160*160*3), dtype=tf.float32))\n",
    "    param = tf.subtract(param, mean)\n",
    "    param = tf.divide(param, std)\n",
    "    return param\n",
    "    \n",
    "def decode(param):\n",
    "    return tf.image.decode_jpeg(param, channels=3, dct_method='INTEGER_ACCURATE')\n",
    "    \n",
    "def get_inputs(param):\n",
    "    \n",
    "    my_input = tf.map_fn(elems=param, fn=decode, dtype=tf.uint8)\n",
    "\n",
    "    my_input = tf.reshape(my_input,[16, 160, 160, 3])\n",
    "    my_input = tf.cast(my_input, dtype=tf.float32)\n",
    "    \n",
    "    my_input = tf.map_fn(elems=my_input, fn=pretreat, dtype=tf.float32)\n",
    "    return my_input\n",
    "\n",
    "MOVING_AVERAGE_DECAY=0.99\n",
    "tf.reset_default_graph()\n",
    "IS_TRAIN=False\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    \n",
    "    global_step=tf.get_variable('global_step',[],initializer=tf.constant_initializer(0),trainable=False)\n",
    "    root_input_placeholder =tf.placeholder(tf.string,shape=(None,16))\n",
    "    input_placeholder = tf.map_fn(elems=root_input_placeholder, fn=get_inputs, dtype=tf.float32)\n",
    "    input_placeholder = tf.reshape(input_placeholder,[-1,16,160,160,3])\n",
    "    logit=inference_p3d(input_placeholder)\n",
    "    variable_averages=tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY,num_updates=global_step)\n",
    "\n",
    "    init=tf.global_variables_initializer()\n",
    "    variable_avg_restore=variable_averages.variables_to_restore()\n",
    "    \n",
    "    saver=tf.train.Saver(variable_avg_restore)\n",
    "    \n",
    "    config = tf.ConfigProto()  \n",
    "    config.gpu_options.allow_growth=True\n",
    "    sess=tf.Session(config=config)\n",
    "    sess.run(init)\n",
    "    #restore your checkpoint file\n",
    "    saver.restore(sess,'./SC_DA_P3D_RES1010_30000-30000')\n",
    "\n",
    "    save_model_to_serving(root_input_placeholder, logit, sess, saver, '1111', './3daction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
