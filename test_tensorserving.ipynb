{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import threading\n",
    "\n",
    "import grpc\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow_serving.apis import predict_pb2\n",
    "from tensorflow_serving.apis import prediction_service_pb2_grpc\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38.65402985 39.78093719 41.80890274]\n",
      " [ 1.49255705  4.94189024 -3.93510246]]\n"
     ]
    }
   ],
   "source": [
    "def pretreat(inputs):\n",
    "        \n",
    "    crop_size = 160\n",
    "    outputs = []\n",
    "    for imggroup in inputs:\n",
    "            \n",
    "        group = []\n",
    "        for image in imggroup:\n",
    "                \n",
    "            height = image.shape[0]\n",
    "            width = image.shape[1]   \n",
    "                        \n",
    "            if(width>height):\n",
    "                scale=float(crop_size)/float(height)\n",
    "                img=np.array(cv2.resize(image,(int(width*scale+1),crop_size))).astype(np.float32)      \n",
    "            else:                    \n",
    "                scale=float(crop_size)/float(width)\n",
    "                img=np.array(cv2.resize(image,(crop_size,int(height*scale+1)))).astype(np.float32)\n",
    "                \n",
    "            crop_y=int((img.shape[0]-crop_size)/2)\n",
    "            crop_x=int((img.shape[1]-crop_size)/2)\n",
    "            img=img[crop_y:crop_y+crop_size,crop_x:crop_x+crop_size,:]\n",
    "\n",
    "            #print img\n",
    "            \n",
    "            std = np.std(img, ddof=1)\n",
    "            mean = np.mean(img)\n",
    "            std = np.max([std, 1.0/np.sqrt(160*160*3)])\n",
    "           \n",
    "            img = (img-mean)/std\n",
    "\n",
    "            group.append(img)\n",
    "            \n",
    "        outputs.append(group)\n",
    "    return np.array(outputs).astype(np.float32)\n",
    "\n",
    "channel = grpc.insecure_channel('127.0.0.1:8500')\n",
    "stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
    "\n",
    "for _ in range(1):\n",
    "    request = predict_pb2.PredictRequest()\n",
    "    request.model_spec.name = '3daction'\n",
    "    request.model_spec.signature_name = 'predict_image'\n",
    "    \n",
    "    dir_path = '/home/sw/Work/tf/yaochang/tests/'\n",
    "    inputs = []\n",
    "    for i in range(16):\n",
    "        file_path = dir_path + '{:0>4}'.format(i) + '.jpg'\n",
    "        img = Image.open(file_path)\n",
    "        inputs.append(np.array(img))\n",
    "        \n",
    "    dir_path = '/home/sw/Work/tf/yaochang/test2/'\n",
    "    inputs2 = []\n",
    "    for i in range(16):\n",
    "        file_path = dir_path + '{:0>4}'.format(i) + '.jpg'\n",
    "        img = Image.open(file_path)\n",
    "        inputs2.append(np.array(img))\n",
    "        \n",
    "    image = pretreat(np.array([inputs,inputs2]))\n",
    "    \n",
    "    request.inputs['x'].CopyFrom(\n",
    "        tf.contrib.util.make_tensor_proto(image))\n",
    "    \n",
    "    result_future = stub.Predict.future(request, 10)  # 5 seconds\n",
    "    exception = result_future.exception()\n",
    "    if exception:\n",
    "        print(exception)\n",
    "    else:\n",
    "        response = numpy.array(\n",
    "        result_future.result().outputs['logit'].float_val)\n",
    "        print response.reshape([2,-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[143.97021484  41.10689545 187.8334198  112.54310608]\n",
      " [ -0.0293625   58.08413696 184.96412659 154.04672241]\n",
      " [  0.64791512  18.9538784  184.80123901 109.82003021]] [0.6036756634712219, 0.48700934648513794, 0.3633933663368225] [0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "def letterbox_image(image, size):\n",
    "    '''resize image with unchanged aspect ratio using padding'''\n",
    "    ih, iw, _ = image.shape\n",
    "\n",
    "    w, h = size\n",
    "    scale = min(w / float(iw), h / float(ih))\n",
    "    \n",
    "    nw = int(iw * scale)\n",
    "    nh = int(ih * scale)\n",
    "\n",
    "    image = cv2.resize(image, (nw, nh), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    new_image = np.ones((416, 416, 3), dtype=np.int8) * 128\n",
    "    new_image[(h - nh) // 2:(h - nh) // 2 + nh, (w - nw) // 2:(w - nw) // 2 + nw, :] = image\n",
    "\n",
    "    return new_image\n",
    "\n",
    "\n",
    "def pretreat(inputs):\n",
    "    boxed_image = letterbox_image(inputs, tuple(reversed((416, 416))))\n",
    "    \n",
    "    image_data = np.array(boxed_image, dtype='float32')\n",
    "    image_data /= 255.\n",
    "    image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
    "\n",
    "    return image_data\n",
    "\n",
    "    \n",
    "file_path = '/home/sw/Work/tf/yaochang/test2/0000.jpg'\n",
    "\n",
    "img = Image.open(file_path)\n",
    "img = np.array(img)\n",
    "\n",
    "image_data = pretreat(img)\n",
    "\n",
    "channel = grpc.insecure_channel('127.0.0.1:8500')\n",
    "stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
    "\n",
    "request = predict_pb2.PredictRequest()\n",
    "request.model_spec.name = 'yolov3'\n",
    "request.model_spec.signature_name = 'detect_image'\n",
    "    \n",
    "request.inputs['x'].CopyFrom(tf.contrib.util.make_tensor_proto(image_data))\n",
    "request.inputs['shape'].CopyFrom(tf.contrib.util.make_tensor_proto([float(img.shape[0]), float(img.shape[1])]))\n",
    "    \n",
    "result_future = stub.Predict.future(request, 10)  # 5 seconds\n",
    "exception = result_future.exception()\n",
    "if exception:\n",
    "    print(exception)\n",
    "else:\n",
    "    out_boxes = numpy.array(result_future.result().outputs['boxes'].float_val).reshape((-1,4))\n",
    "    out_scores = result_future.result().outputs['scores'].float_val\n",
    "    out_classes = result_future.result().outputs['classes'].int_val\n",
    "    print out_boxes, out_scores, out_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection model, /home/sw/Work/tf/yaochang/weights/trained_weights_final.h5 model, 9 anchors, and 1 classes load success!.\n",
      "<type 'int'> <type 'int'> <type 'int'> <type 'int'>\n",
      "2.23655913978\n",
      "[[143.97023     41.10689    187.83342    112.54312   ]\n",
      " [ -0.0293625   58.08414    184.96413    154.04672   ]\n",
      " [  0.64793175  18.953882   184.80122    109.820015  ]] [0.60367596 0.48700902 0.3633928 ] [0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from Yolo3 import YOLO\n",
    "\n",
    "file_path = '/home/sw/Work/tf/yaochang/test2/0000.jpg'\n",
    "\n",
    "img = Image.open(file_path)\n",
    "image = np.array(img)\n",
    "\n",
    "person_detect_model = YOLO()\n",
    "out_boxes, out_scores, out_classes = person_detect_model.get_box(image)\n",
    "print out_boxes, out_scores, out_classes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
